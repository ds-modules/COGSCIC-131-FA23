{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0d0ef60",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #c1f2a5\">\n",
    "\n",
    "\n",
    "# PS7\n",
    "\n",
    "**BECAUSE THIS IS THE FINAL PROBLEM SET, MOST QUESTIONS ARE [SOLO] QUESTIONS.**\n",
    "\n",
    "You are NOT allowed to ask your peers or any of the GSIs for help on [SOLO] questions. However, you can post _clarification_ questions on Ed if anything about the instructions or content of the problem set is unclear. Any questions asking for hints or debugging help will be disregarded. \n",
    "    \n",
    "\n",
    "**Note: unlike previous problem sets which had 2 parts, PS7 has 3 parts. Each part can be done independently. Parts 2 and 3 are much shorter than part 1.**  \n",
    "    \n",
    "</div> \n",
    "\n",
    "----\n",
    "\n",
    "<div style=\"background-color: #c1f2a5\">\n",
    "    \n",
    "# Part 1\n",
    "\n",
    "In Part 1 of this problem set, you are going to implement an exemplar model and a prototype model, and evaluate their predictions.\n",
    "    \n",
    "## Instructions\n",
    "\n",
    "Remember to do your problem set in Python 3. Make sure you fill in any place that says `#YOUR CODE HERE` or \"YOUR ANSWER HERE\".\n",
    "\n",
    "Unless we specify otherwise, make sure: \n",
    "- that all plots are scaled in such a way that you can see what is going on (while still respecting specific plotting instructions) \n",
    "- that the general patterns are fairly represented.\n",
    "- to label all x- and y-axes, and to include a title.\n",
    "    \n",
    "**Test cases are here to help you debug your code but passing them is not a guarantee that your code is correct.**\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91254e52",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nose.tools import assert_equal\n",
    "from numpy.testing import assert_array_equal, assert_almost_equal\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442c4a61",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5acf6c",
   "metadata": {},
   "source": [
    "## Q1 Coding Tversky's Contrast Model\n",
    "This part of the problem set explores exemplar and prototype models. \n",
    "\n",
    "Let's start with an examplar model we saw in class: Tversky's constrast model.\n",
    "\n",
    "Recall from lecture and readings that Tversky defined the similarity between objects $a$ and $b$ as:\n",
    "\n",
    "$$\n",
    "S(a,b) = \\theta\\cdot f(A \\cap B) - \\alpha\\cdot f(A - B) - \\beta\\cdot f(B-A)\n",
    "$$\n",
    "\n",
    "Here, $a$ and $b$ are the two objects being compared, $A$ is the set of features of $a$, $B$ is the set of features of $b$, $f$ is an additive function that maps sets to numbers, and $\\theta, \\alpha, \\beta$ are free parameters all $\\ge 0$.\n",
    "\n",
    "In this set of questions, you will write code to implement Tversky's contrast model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e0ba7a",
   "metadata": {
    "deletable": false
   },
   "source": [
    "We will compute each part of the similarity function in turn. First, we need to compute $f(A\\cap B)$, which is essentially the *number of features that $A$ and $B$ have in common*. As an example, consider the following fruits:\n",
    "\n",
    "|            | Sweet | Sour  | Bitter | Salty | Seeds |\n",
    "|:-----------|:-----:|:-----:|:------:|:-----:|:-----:|\n",
    "| Orange     | 1     | 1     | 0      | 0     | 1     |\n",
    "| Lemon      | 0     | 1     | 1      | 0     | 1     |\n",
    "\n",
    "The information in the table above could also be stored in a NumPy array, where `True` means the fruit has a feature and `False` means it does not. So, the features of \"orange\" and \"lemon\" could be represented as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7189e2",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "orange_features = np.array([True,  True,  False, False, True ])\n",
    "lemon_features  = np.array([False, True,  True,  False, True ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafd4572",
   "metadata": {
    "deletable": false
   },
   "source": [
    "What is the number of features that orange and lemon have in common? A feature only counts as being \"in common\" if *both* feature vectors have it, so in this case, the only common features between orange and lemon are \"sour\" and \"seeds\" (not \"salty\", because neither of them have this feature). Thus, orange and lemon have two features in common.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050c0c04",
   "metadata": {},
   "source": [
    "### Q1.1 Common features [2pts, HELP]\n",
    "\n",
    "Complete the function <code>common_features</code> below so that it takes two binary feature vectors of length $n$ (<code>a</code> and <code>b</code>) as arguments and returns the total number of features in common between <code>a</code> and <code>b</code>. Here, we define the \"number of common features\" as the number of cells that are <code>True</code> in both <code>a</code> and <code>b</code> arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e53e857",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "da924ec15b466f84257b93c5364bd642",
     "grade": false,
     "grade_id": "common_features",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def common_features(a, b):\n",
    "    \"\"\"\n",
    "    Compute the number of common features between a and b. Features \n",
    "    count as being shared between the vectors if they are present in\n",
    "    both vectors (i.e., they are a 1 in both). In other words, you should\n",
    "    compute the intersection of features between a and b.\n",
    "    \n",
    "    Hint: your solution can be done in a single line of code, including\n",
    "    the return statement.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    a, b : boolean numpy array with shape (n,)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    number of common features between a and b\n",
    "    \n",
    "    \"\"\"\n",
    "    #YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9363f7",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Test your `common_features` function on the orange and lemon features, to see if it does in fact return 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f514db",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "print(r\"f(orange ∩ lemon) = \" + str(common_features(orange_features, lemon_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c66a0d5",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# optional: add your own test cases here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b232af",
   "metadata": {},
   "source": [
    "Test the `common_features` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4794b074",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "22c298084eaa9c4b718fd285ba5f3616",
     "grade": true,
     "grade_id": "test_common_features",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert_equal(common_features(np.array([True, True, False, False]), np.array([True, True, False, False])), 2)\n",
    "assert_equal(common_features(np.array([True, False, False, False]), np.array([True, True, False, False])), 1)\n",
    "assert_equal(common_features(np.array([True, False, True, False]), np.array([True, True, False, False])), 1)\n",
    "assert_equal(common_features(np.array([False, False, False, False]), np.array([False, False, False, False])), 0)\n",
    "assert_equal(common_features(np.array([True, True, True, True]), np.array([True, True, True, True])), 4)\n",
    "print(\"Success!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7d932f",
   "metadata": {},
   "source": [
    "Below, we define some test features to try. The following cell uses your function `common_features` to plot the shared features between multiple arrays. \n",
    "\n",
    "It's missing some things to make it a good figure: add axes labels, axes ticks, and a title to make it clear what the image is showing. \n",
    "\n",
    "Once you have made the necessary changes to the plot (NOT the data!), save your figure as `PS7_Q1_1.png` and upload it to Gradescope. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3e536a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL!\n",
    "\n",
    "# Generate all possible combinations of True and False for size 3\n",
    "all_combinations = list(product([True, False], repeat=3))\n",
    "# Convert the combinations to NumPy arrays\n",
    "all_arrays = [np.array(combination) for combination in all_combinations]\n",
    "\n",
    "shared_features = np.zeros([8,8])\n",
    "\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        shared_features[i,j] = int(common_features(all_arrays[i],all_arrays[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e20dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EDIT THIS CELL OR ADD NEW LINES TO ADD WHAT IS MISSING FROM THIS FIGURE\n",
    "\n",
    "# Plot the array as a colormap\n",
    "plt.imshow(shared_features, cmap='viridis')  # 'viridis' is just an example colormap; you can choose any other colormap\n",
    "\n",
    "# Add a colorbar for reference\n",
    "plt.colorbar()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig('PS7_Q1_1.png') # uncomment this line when you have made your modifications and are ready to save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a61fb61",
   "metadata": {
    "deletable": false
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e323bf9a",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q1.2 Differences in features [2pts, SOLO]\n",
    "To complete Tversky's equation, we also need to compute $f(A-B)$ and $f(B-A)$. This can be done using the same operation: counting the number of features that are in one vector, but not the other. As an example, let's take a look at some more fruits:\n",
    "\n",
    "|            | Sweet | Sour  | Bitter | Salty | Seeds |\n",
    "|:-----------|:-----:|:-----:|:------:|:-----:|:-----:|\n",
    "| Grapefruit | 1     | 1     | 1      | 0     | 1     |\n",
    "| Banana     | 1     | 0     | 0      | 0     | 0     |\n",
    "\n",
    "If we wanted to compute $f(\\text{grapefruit}-\\text{banana})$, we want to count the number of features grapefruit has that banana does not. \n",
    "\n",
    "In this case, there are three features matching this description: \"sour\", \"bitter\", and \"seeds\", so $f(A-B)$ should return $3$. Similarly, to compute $f(\\text{banana}-\\text{grapefruit})$, we want to count features that are in banana but not in grapefruit. In these example, there are actually *no* features that the banana has that the grapefruit does not, so $f(B-A)$ should return $0$.\n",
    "\n",
    "Complete the function `differences` so that it takes two binary feature vectors of length $n$ (`a` and `b`, just like before) as arguments and returns the total number of features in `a` that are not contained in `b`. This is defined as the number of cells that are `True` in `a` and `False` in `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb9301a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8f22271ed780158a4f6c8ca4dd6d2986",
     "grade": false,
     "grade_id": "differences",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def differences(a, b):\n",
    "    \"\"\"\n",
    "    Compute the number of features that belong to a, but not b. Features \n",
    "    count as being in a but not b if the feature is 1 in a, and 0 in b.\n",
    "    \n",
    "    Hint: your solution can be done in a single line of code, including\n",
    "    the return statement.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    a, b : boolean numpy array with shape (n,)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    number of differences between a and b\n",
    "    \n",
    "    \"\"\"\n",
    "    #YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c096138e",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Test your `differences` function on the orange and lemon feature vectors to see if it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7772b3",
   "metadata": {
    "deletable": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define the feature vectors\n",
    "grapefruit_features = np.array([True,  True,  True,  False, True ])\n",
    "banana_features     = np.array([True,  False, False, False, False])\n",
    "\n",
    "print(\"f(grapefruit - banana) = \" + str(differences(grapefruit_features, banana_features)))\n",
    "print(\"f(banana - grapefruit) = \" + str(differences(banana_features, grapefruit_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f605b73",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# optional: add your own test cases here!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa47f74",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "31dba14330b9b48e36a322cf3fa97bf1",
     "grade": true,
     "grade_id": "test_differences",
     "locked": false,
     "points": 0.5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Test your differences function.\"\"\"\n",
    "assert_equal(differences(np.array([True, True, False, False]), np.array([True, True, False, False])), 0)\n",
    "assert_equal(differences(np.array([True, False, False, False]), np.array([True, True, False, False])), 0)\n",
    "assert_equal(differences(np.array([True, False, True, False]), np.array([True, True, False, False])), 1)\n",
    "assert_equal(differences(np.array([True, True, True, True]), np.array([False, False, False, False])), 4)\n",
    "assert_equal(differences(np.array([True, True, True, True]), np.array([False, False, False, True])), 3)\n",
    "assert_equal(differences(np.array([False, False, False, False]), np.array([False, False, False, False])), 0)\n",
    "assert_equal(differences(np.array([True, True, True, True]), np.array([True, True, True, True])), 0)\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdeb2e6",
   "metadata": {},
   "source": [
    "Below, we define some test features to try. The following cell uses your function `differences` to plot the shared features between multiple arrays. \n",
    "\n",
    "It's missing some things to make it a good figure: add axes labels, axes ticks, and a title to make it clear what the image is showing. \n",
    "\n",
    "Once you have made the necessary changes to the plot (NOT the data!), save your figure as `PS7_Q1_2.png` and upload it to Gradescope. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aaf92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL!\n",
    "\n",
    "# Generate all possible combinations of True and False for size 3\n",
    "all_combinations = list(product([True, False], repeat=3))\n",
    "# Convert the combinations to NumPy arrays\n",
    "all_arrays = [np.array(combination) for combination in all_combinations]\n",
    "\n",
    "shared_features = np.zeros([8,8])\n",
    "\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        shared_features[i,j] = int(differences(all_arrays[i],all_arrays[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167eef63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EDIT THIS CELL OR ADD NEW LINES TO ADD WHAT IS MISSING FROM THIS FIGURE\n",
    "\n",
    "# Plot the array as a colormap\n",
    "plt.imshow(shared_features, cmap='viridis')  # 'viridis' is just an example colormap; you can choose any other colormap\n",
    "\n",
    "# Add a colorbar for reference\n",
    "plt.colorbar()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig('PS7_Q1_2.png')  # uncomment this line when you have made your modifications and are ready to save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c825187",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3042916f",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q1.3 Tversky's similarity [4pts, SOLO]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0047ecf2",
   "metadata": {
    "deletable": false
   },
   "source": [
    "You now have all the elements you need to implement the equation for Tverky's similarity. \n",
    "Using your completed functions `common_features` and `differences`, complete Tversky's similarity function in `tversky_sim` below according to the quation provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8685e0b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c9ac47fab00c0c69e5d718535ca1acc2",
     "grade": false,
     "grade_id": "tversky_sim",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def tversky_sim(a, b, theta=1.0, alpha=0.5, beta=0.5):\n",
    "    \"\"\"\n",
    "    Compute Tversky's similarity function for two vectors a and b:\n",
    "    \n",
    "    S(a, b) = theta*f(a ∩ b) - alpha*f(a - b) - beta*f(b - a)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    a, b : boolean numpy array with shape (n,)\n",
    "    theta, alpha, beta : parameters of the similarity function\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    the similarity between a and b : float\n",
    "    \n",
    "    \"\"\"\n",
    "    #YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d70a30b",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# optional: add your own test cases here!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a90088",
   "metadata": {},
   "source": [
    "Run the cell below to test your `tversky_sim` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd97d845",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "812829d3c0f655de76c20f5323652727",
     "grade": true,
     "grade_id": "test_tversky_sim",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.array([True, True, True, False, False, False])\n",
    "y = np.array([False, True, True, True, False, True])\n",
    "\n",
    "# check some explicit values\n",
    "assert_equal(tversky_sim(x, y), 0.5)\n",
    "assert_equal(tversky_sim(y, x), 0.5)\n",
    "assert_equal(tversky_sim(x, y, theta=2.0), 2.5)\n",
    "assert_equal(tversky_sim(y, x, theta=2.0), 2.5)\n",
    "assert_equal(tversky_sim(x, y, alpha=1.0), 0.0)\n",
    "assert_equal(tversky_sim(y, x, alpha=1.0), -0.5)\n",
    "assert_equal(tversky_sim(x, y, beta=1.5), -1.5)\n",
    "assert_equal(tversky_sim(y, x, beta=1.5), -0.5)\n",
    "\n",
    "# check that it uses common_featues\n",
    "old_common_features = common_features\n",
    "del common_features\n",
    "try:\n",
    "    tversky_sim(x, y)\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\"tversky_sim does not use common_features\")\n",
    "finally:\n",
    "    common_features = old_common_features\n",
    "    del old_common_features\n",
    "\n",
    "# check that it uses differences\n",
    "old_differences = differences\n",
    "del differences\n",
    "try:\n",
    "    tversky_sim(x, y)\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\"tversky_sim does not use differences\")\n",
    "finally:\n",
    "    differences = old_differences\n",
    "    del old_differences\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a275cadc",
   "metadata": {},
   "source": [
    "Below, we define some test features to try. The following cell calls your function `tversky_sim` to plot the shared features between multiple arrays. \n",
    "\n",
    "It's missing some things to make it a good figure: add axes labels, axes ticks, titles, and a global title for the parent figure to make it clear what the image is showing. \n",
    "\n",
    "Once you have made the necessary changes to the plot (NOT the data!), save your figure as `PS7_Q1_3.png` and upload it to Gradescope. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4602a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL!\n",
    "\n",
    "# Generate all possible combinations of True and False for size 3\n",
    "all_combinations = list(product([True, False], repeat=3))\n",
    "# Convert the combinations to NumPy arrays\n",
    "all_arrays = [np.array(combination) for combination in all_combinations]\n",
    "\n",
    "shared_features1 = np.zeros([8,8])\n",
    "shared_features2 = np.zeros([8,8])\n",
    "\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        shared_features1[i,j] = int(tversky_sim(all_arrays[i],all_arrays[j],theta=2))\n",
    "        shared_features2[i,j] = int(tversky_sim(all_arrays[i],all_arrays[j],theta=2,alpha=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade741f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EDIT THIS CELL OR ADD NEW LINES TO ADD WHAT IS MISSING FROM THIS FIGURE\n",
    "\n",
    "# Create subplots with a 1x2 grid\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "    \n",
    "im1 = axs[0].imshow(shared_features1, cmap='viridis')\n",
    "fig.colorbar(im1, ax=axs[0])\n",
    "im2 = axs[1].imshow(shared_features2, cmap='viridis')\n",
    "fig.colorbar(im2, ax=axs[1])\n",
    "# Adjust layout to prevent clipping of titles\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# fig.savefig(\"PS7_Q1_3.png\") # uncomment this line when you have made your modifications and are ready to save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcee816",
   "metadata": {},
   "source": [
    "---\n",
    "## Q2 Applying Tversky's Contrast Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da42ec07",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q2.1 Find similar animals [4pts, SOLO]\n",
    "Now that we have a way of quantifying similarity, let's apply it to some real data. Here we have provided you with a dataset that includes 50 animals and 80 features, and specifies which animals have which features.\n",
    "\n",
    "First, let's load our data in. There are three arrays in the data: `feature_names`, `animal_names`, and `animal_features`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d276dda",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "data = np.load(\"50animals.npz\")\n",
    "[k for k in data.keys()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d99c43a",
   "metadata": {
    "deletable": false
   },
   "source": [
    "The `animal_features` array is a $50\\times 80$ boolean array of features, where each row corresponds to a different animal, and each column corresponds to a different feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e571c4",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "animal_features = data['animal_features']\n",
    "animal_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de798071",
   "metadata": {
    "deletable": false
   },
   "source": [
    "And `animal_names` is a vector of length $50$ containing the animal names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74752096",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "animal_names = data['animal_names']\n",
    "animal_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3bbb85",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Similarly, the `feature_names` array is a vector of length 85 of the feature names. We actually won't need it for this problem, though, so we won't create a new variable for it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fedeb6c",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Complete the function `find_similar_animals_tversky` to take the name of an animal and find the **5 most similar animals** to that animal, using your function `tversky_sim`. You should return the animals in order of most similar to least similar **excluding** the test animal itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140f1800",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Note: the `np.argsort()` function will come in handy here (take a look at Problem Set 0 if you forgot how it's used). To keep ties in the original order, make sure to use `mergesort` argument (which is [stable](http://programmers.stackexchange.com/a/247441)) like so:\n",
    "\n",
    "```\n",
    "indices = np.argsort(array, kind='mergesort')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e435e76",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c81d9bad0684cd708eceb7617481b00b",
     "grade": false,
     "grade_id": "find_similar_animals",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def find_similar_animals_tversky(name, features, animal_names):\n",
    "    \"\"\"\n",
    "    Finds the five most similar animals to the given animal. You should return the\n",
    "    animals in order from most similar to least similar to the given animal. In\n",
    "    addition, you should NOT include the given animal in the list of animals you\n",
    "    return. \n",
    "    \n",
    "    If two animals have the same similarity score, find_similar_animals \n",
    "    should break ties in the REVERSE of the order they appear in animal_names \n",
    "    (e.g., if the first two entries in animal_names are A and B, and both animals \n",
    "    A and B have the same similarity to target animal C, find_similar_animals should \n",
    "    place B BEFORE A when ranking them in terms of their similarity to C.)\n",
    "    \n",
    "    Hint: your solution can be done in 4 lines of code, including the return\n",
    "    statement.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    name : string\n",
    "        the name of an animal\n",
    "    features : boolean numpy array\n",
    "        animals by features, with shape (n, m)\n",
    "    animal_names : list of strings\n",
    "        list of animal names with length n\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    a list of five animal names, ordered by most to least similar with ties in the original order\n",
    "    \n",
    "    \"\"\"\n",
    "    #YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602c0f38",
   "metadata": {},
   "source": [
    "Test the `find_similar_animals` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c326f6",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a5f4c2b41df4dbcd1bff5f3b8cc02eed",
     "grade": true,
     "grade_id": "test_find_similar_animals",
     "locked": false,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "def assert_one_equal(arr, *others):\n",
    "    for other in others:\n",
    "        if arr == other:\n",
    "            return\n",
    "    assert_equal(arr, others[0])\n",
    "\n",
    "# load the animal data\n",
    "data = np.load(\"50animals.npz\")\n",
    "af = data['animal_features']\n",
    "an = data['animal_names']\n",
    "data.close()\n",
    "\n",
    "# try finding animals similar to mouse\n",
    "assert_array_equal(\n",
    "    find_similar_animals_tversky('mouse', af, an),\n",
    "    ['rat', 'rabbit', 'weasel', 'hamster', 'squirrel'])\n",
    "\n",
    "# try finding animals similar to grizzly bear\n",
    "assert_array_equal(\n",
    "    find_similar_animals_tversky('grizzly bear', af, an),\n",
    "    ['bobcat', 'polar bear', 'raccoon', 'lion', 'gorilla'])\n",
    "\n",
    "# try finding animals similar to grizzly bear with different features\n",
    "assert_array_equal(\n",
    "    find_similar_animals_tversky('grizzly bear', ~af, an),\n",
    "    ['polar bear', 'gorilla', 'german shepherd', 'bobcat', 'raccoon'])\n",
    "\n",
    "# try finding animals similar to grizzly bear with different names\n",
    "assert_array_equal(\n",
    "    find_similar_animals_tversky('grizzly bear', af, an[::-1]),\n",
    "    ['weasel', 'beaver', 'buffalo', 'tiger', 'collie'])\n",
    "\n",
    "# try finding animals similar to grizzly bear with both different names and features\n",
    "assert_array_equal(\n",
    "    find_similar_animals_tversky('grizzly bear', ~af, an[::-1]),\n",
    "    ['spider monkey', 'seal', 'weasel', 'dalmatian', 'giraffe'])\n",
    "\n",
    "# check that it uses tversky_sim\n",
    "old_tversky_sim = tversky_sim\n",
    "del tversky_sim\n",
    "try:\n",
    "    find_similar_animals_tversky('mouse', af, an)\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\"find_similar_animals does not use tversky_sim\")\n",
    "finally:\n",
    "    tversky_sim = old_tversky_sim\n",
    "    del old_tversky_sim\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d021ba8",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# optional: add your own test cases here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e086d9aa",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Now, you can use your function to find out which animals are most similar to a mouse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca84e11c",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# should print ['rat', 'rabbit', 'weasel', 'hamster', 'squirrel']\n",
    "# make sure you have excluded 'mouse' itself from the top 5 most similar animals!\n",
    "print(f\"The 5 animals that are most similar to 'mouse' are: {find_similar_animals_tversky('mouse', animal_features, animal_names)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d919c3a",
   "metadata": {},
   "source": [
    "Copy-paste the output of the two cells below in Gradescope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05220e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2.1 (A)\n",
    "# PASTE THE OUTPUT OF THIS CELL INTO GRADESCOPE \n",
    "print(find_similar_animals_tversky('giraffe', animal_features, animal_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5707870",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Q2.1 (B)\n",
    "# PASTE THE OUTPUT OF THIS CELL INTO GRADESCOPE \n",
    "print(find_similar_animals_tversky('grizzly bear', ~af, an[::-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b45942",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75f1a59",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q2.2 Find similar animals to the giant panda [4pts, SOLO]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1a770c",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Run your function `find_similar_animals_tversky` for the input 'giant panda':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cc22b7",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "print(find_similar_animals_tversky('giant panda', animal_features, animal_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaecb42a",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Answer the following questions in Gradescope:\n",
    "\n",
    "A) What are the five most similar animals to `giant panda` that your function returned? Do they match your intuition (that is, if you were to intuitively pick out the five most similar animals to a giant panda (from the `animal_names` list), would you pick those five in that order)? (**2 points**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c479358",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4cedc4",
   "metadata": {},
   "source": [
    "B) If yes, why do you think Tversky's contrast model did a good job at capturing your intuition? If no, what aspect(s) of Tversky's contrast model led the results to misalign with your intuition? (**2 points**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0534c8",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0a5ed6",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e64005",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Q2.3 Variant vs. prototype [4pts, SOLO]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada12fdd",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Tversky's contrast model takes optional parameters, $\\theta$, $\\alpha$, and $\\beta$, which bias the similarity more or less towards shared features versus feature differences. Recall from lecture that Tversky's notion of similarity says that the similarity of the *variant* to the *prototype* should be greater than the similarity of the *prototype* to the *variant*. More formally, if $a$ is the prototype and $b$ is the variant, then:\n",
    "\n",
    "$$\n",
    "S(b,a) − S(a,b) = (\\alpha −\\beta)[ f (A − B) − f (B − A)]\n",
    "$$\n",
    "\n",
    "Given this equation, $S(b,a)>S(a,b)$ when $\\alpha>\\beta$ *and* $f(A-B)>f(B-A)$. That is, when the prototype has more distinctive or heavily weighted features than the variant. Previously, we used the same value for both $\\alpha$ and $\\beta$, meaning that $S(b,a)=S(a,b)$. However, if we change these parameters, we can get asymmetric similarities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb28d11",
   "metadata": {},
   "source": [
    "Let's explore this idea a little further using the leopard and the tiger. \n",
    "\n",
    "Answer the following three questions in Gradescope:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34116fe",
   "metadata": {
    "deletable": false
   },
   "source": [
    "A) First, which animal you would intuitively say is more prototypical: the leopard or the tiger? Why? Answer in **at most 2 sentences**. (**0.5 points**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d6b512",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5492d4d",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Now, run the cell below to find out what Tversky's similarity metric says about the similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3297f31a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "9bad7b5d7d43f5bb8c2786f8ce6b710a",
     "grade": false,
     "grade_id": "bat_mouse_similarity",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "leopard = animal_features[animal_names=='leopard']\n",
    "tiger = animal_features[animal_names=='tiger']\n",
    "print(\"S(leopard, tiger) = {}\".format(tversky_sim(leopard, tiger, theta=1.0, alpha=2.5, beta=0.5)))\n",
    "print(\"S(tiger, leopard) = {}\".format(tversky_sim(tiger, leopard, theta=1.0, alpha=2.5, beta=0.5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42903cf",
   "metadata": {
    "deletable": false
   },
   "source": [
    "B) What numbers did you get? Does Tversky's similarity metric say that a leopard is more similar to a tiger, or vice versa? Does this mean that Tversky's similarity metric says (in this case) that the prototype is more similar to the variant, or that the variant is more similar to the prototype? (**1.5 points**)\n",
    "\n",
    "(Hint: What animal category are leopards and tigers members of? Which do you think is a more \"prototypical\" example of this category?) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc56468",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcc43ad",
   "metadata": {
    "collapsed": true,
    "deletable": false
   },
   "source": [
    "C) Can Tversky's leopard vs. tiger similarity results be interpreted as counter-evidence for his notion that $S$(variant, prototype) $>$ $S$(prototype, variant), where $S$ is the similarity function? (**2 points**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fa4aec",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d43e78c",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Q3 Coding a Prototype Model\n",
    "Let's now switch gears and move to a prototype model. We will first code it and then apply it to the same dataset as before. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8827b26",
   "metadata": {},
   "source": [
    "In this set of questions, you will write code to implement the prototype theory of categorization based on Shepard's universal law for calculating the similarity between pairs of stimuli. \n",
    "\n",
    "Recall that the features of the prototype should be determined by a \"majority rule\" vote between the members of the category: if **half or more** of the members in a category have a particular feature, the category prototype should have that feature; otherwise, it should not. For example, let's again say we have features for some fruits:\n",
    "\n",
    "|            | Sweet | Sour  | Bitter | Salty | Seeds |\n",
    "|:-----------|:-----:|:-----:|:------:|:-----:|:-----:|\n",
    "| Apple      | 1     | 0     | 0      | 0     | 1     |\n",
    "| Orange     | 1     | 1     | 0      | 0     | 1     |\n",
    "| Lemon      | 0     | 1     | 1      | 0     | 1     |\n",
    "| Grapefruit | 1     | 1     | 1      | 0     | 1     |\n",
    "| Banana     | 1     | 0     | 0      | 0     | 0     |\n",
    "| Tomato     | 1     | 0     | 0      | 0     | 1     |\n",
    "\n",
    "As a NumPy array, the features of all fruits would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133a110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_features = np.array([\n",
    "    [True,  False, False, False, True ],\n",
    "    [True,  True,  False, False, True ],\n",
    "    [False, True,  True,  False, True ],\n",
    "    [True,  True,  True,  False, True ],\n",
    "    [True,  False, False, False, False],\n",
    "    [True,  False, False, False, True ]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09198e9",
   "metadata": {},
   "source": [
    "The prototype for these features would then be:\n",
    "\n",
    "| Sweet | Sour | Bitter | Salty | Seeds | \n",
    "|:-----:|:----:|:------:|:-----:|:-----:|\n",
    "| 1     | 1    | 0      | 0     | 1     |\n",
    "\n",
    "because 5 of 6 fruits have the \"sweet\" feature, 3 of 6 fruits have the \"sour\" feature, 2 of 6 fruits have the \"bitter\" feature, 0 of 6 fruits have the \"salty\" feature, and 5 of 6 fruits have the \"seeds\" feature. As a NumPy array, this could be represented as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d26f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_prototype = np.array([True, True, False, False, True])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68de28e9",
   "metadata": {},
   "source": [
    "### Q3.1 Implement `prototype` [2pts, HELP]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fe85ca",
   "metadata": {},
   "source": [
    "Implement the function `prototype` below. It should take an $n\\times m$ features array (with $n$ category elements and $m$ features per element) and return the features of the prototype for that category.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15f9be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prototype(features):\n",
    "    \"\"\"\n",
    "    Compute the prototype features, based on the given features of\n",
    "    category members. The prototype should have a feature if half or\n",
    "    more of the category members have that feature.\n",
    "\n",
    "    Hint: this function is similar to the `threshold` function from\n",
    "    Problem Set 0.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    features : boolean numpy array with shape (n, m)\n",
    "        The first dimension corresponds to n category members, and the\n",
    "        second dimension to m features.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    boolean numpy array with shape (m,) corresponding to the features\n",
    "    of the prototype of the category members\n",
    "    \n",
    "    \"\"\"\n",
    "    #YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1b2458",
   "metadata": {},
   "source": [
    "Test your function on the fruit features, to see if it gives the right prototype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cd1c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Actual prototype:   \" + str(fruit_prototype))\n",
    "print(\"Computed prototype: \" + str(prototype(fruit_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bde4486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# opyional: add your test cases here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3919a30b",
   "metadata": {},
   "source": [
    "Test the `prototype` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b34422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure it works for features that are half or more\n",
    "assert_array_equal(prototype(np.array([[0, 1], [0, 0]], dtype=bool)), np.array([0, 1]))\n",
    "\n",
    "for i in range(10):\n",
    "    # create a random array of features\n",
    "    n, m = np.random.randint(10, 100, 2)\n",
    "    features = np.random.randint(0, 2, (n, m)).astype(bool)\n",
    "    \n",
    "    # compute the prototype\n",
    "    proto = prototype(features)\n",
    "    \n",
    "    # check the shape and type\n",
    "    assert_equal(proto.shape, (m,), \"incorrect shape for the prototype array\")\n",
    "    assert_equal(proto.dtype, bool, \"prototype is not a boolean array\")\n",
    "    \n",
    "    # check that the prototype is correct\n",
    "    for j in range(m):\n",
    "        count = features[:, j].sum()\n",
    "        if count >= (n / 2) and not proto[j]:\n",
    "            raise AssertionError(\"prototype should have feature {}, but it doesn't\".format(j))\n",
    "        elif count < (n / 2) and proto[j]:\n",
    "            raise AssertionError(\"prototype should NOT have feature {}, but it does\".format(j))\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e7c272",
   "metadata": {},
   "source": [
    "Copy-paste your `prototype` function into Gradescope."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5be14c1",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Q3.2 Shepard's similarity [2pts, SOLO]\n",
    "\n",
    "According to **Shepard's Universal Law of Generalization**, the similarity between two feature vectors is defined as follows:\n",
    "\n",
    "> For binary feature vectors ${\\bf a}$ and ${\\bf b}$, define a function $d:(\\{0,1\\}^n, \\{0,1\\}^n) \\rightarrow \\mathbb{Z}$ such that $d({\\bf a},{\\bf b})$ is the number of features (positions) by which ${\\bf a}$ and ${\\bf b}$ differ. The similarity between ${\\bf a}$ and ${\\bf b}$ may be calculated as $s({\\bf a},{\\bf b}) = e^{-d({\\bf a},{\\bf b})}$.\n",
    "\n",
    "Note that because we are using binary feature representations, $d({\\bf a},{\\bf b})$ corresponds to the Hamming distance between ${\\bf a}$ and ${\\bf b}$, rather than the Euclidean distance as we saw in previous problem sets. \n",
    "\n",
    "Returning to our fruits example from earlier, let's see how this works when computing the similarity between grapefruit and banana:\n",
    "\n",
    "|            | Sweet | Sour  | Bitter | Salty | Seeds |\n",
    "|:-----------|:-----:|:-----:|:------:|:-----:|:-----:|\n",
    "| Grapefruit | 1     | 1     | 1      | 0     | 1     |\n",
    "| Banana     | 1     | 0     | 0      | 0     | 0     |\n",
    "\n",
    "Following Shepard's Universal Law of Generalization, the first step is to identify the number of features on which the two elements differ. In this case, there are three features in which grapefruit and banana differ: the \"sour\", \"bitter\", and \"seeds\" features. So, $d(\\text{grapefruit},\\text{banana})=3$. Thus, the similarity would be:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "s(\\text{grapefruit},\\text{banana})&=e^{-d(\\text{grapefruit},\\text{banana})}\\\\\n",
    "&=e^{-3}\\\\\n",
    "&=0.049787068367863944\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e74409f",
   "metadata": {},
   "source": [
    "Implement the function `shepard_sim`, which takes two binary feature vectors of length $m$, `a` and `b`, and returns a value between $0$ and $1$ representing the similarity between the two inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e8cec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shepard_sim(a, b):\n",
    "    \"\"\"\n",
    "    Computes the similarity between binary feature vectors a and b, using\n",
    "    Shepard's law of generalization:\n",
    "    \n",
    "    S(a, b) = e^(-d(a, b))\n",
    "    \n",
    "    where d(a, b) corresponds to the number of locations where a and b differ\n",
    "    (i.e., a=1 and b=0, or a=0 and b=1).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    a, b : boolean numpy array with shape (m,)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    similarity between a and b : float\n",
    "    \n",
    "    \"\"\"\n",
    "    #YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3dcb7c",
   "metadata": {},
   "source": [
    "Test the `shepard_sim` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c00121",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([ True, False,  True,  True,  True,  True], dtype=bool)\n",
    "b = np.array([ True,  True,  True, False, False, False], dtype=bool)\n",
    "assert_almost_equal(shepard_sim(a, b), 0.01831563888873418)\n",
    "\n",
    "a = np.array([False,  True,  True,  True,  True, False,  True,  True,  True,\n",
    "       False, False, False, False, False, False,  True], dtype=bool)\n",
    "b = np.array([False,  True, False,  True, False, False, False, False,  True,\n",
    "       False,  True,  True, False, False, False,  True], dtype=bool)\n",
    "assert_almost_equal(shepard_sim(a, b), 0.0024787521766663585)\n",
    "\n",
    "a = np.array([ True,  True, False,  True], dtype=bool)\n",
    "b = np.array([ True,  True,  True, False], dtype=bool)\n",
    "assert_almost_equal(shepard_sim(a, b), 0.1353352832366127)\n",
    "\n",
    "a = np.array([ True], dtype=bool)\n",
    "b = np.array([ True], dtype=bool)\n",
    "assert_almost_equal(shepard_sim(a, b), 1.0)\n",
    "\n",
    "a = np.array([False,  True,  True, False,  True,  True,  True], dtype=bool)\n",
    "b = np.array([False,  True, False, False, False,  True,  True], dtype=bool)\n",
    "assert_almost_equal(shepard_sim(a, b), 0.1353352832366127)\n",
    "\n",
    "a = np.array([False, False], dtype=bool)\n",
    "b = np.array([False, False], dtype=bool)\n",
    "assert_almost_equal(shepard_sim(a, b), 1.0)\n",
    "\n",
    "a = np.array([ True,  True,  True, False,  True, False,  True,  True,  True,\n",
    "       False, False,  True,  True, False,  True], dtype=bool)\n",
    "b = np.array([ True, False,  True,  True, False,  True, False, False,  True,\n",
    "       False,  True, False,  True,  True, False], dtype=bool)\n",
    "assert_almost_equal(shepard_sim(a, b), 4.5399929762484854e-05)\n",
    "\n",
    "a = np.array([False,  True, False], dtype=bool)\n",
    "b = np.array([ True,  True, False], dtype=bool)\n",
    "assert_almost_equal(shepard_sim(a, b), 0.36787944117144233)\n",
    "\n",
    "a = np.array([False,  True,  True,  True,  True,  True,  True], dtype=bool)\n",
    "b = np.array([False, False,  True,  True,  True, False,  True], dtype=bool)\n",
    "assert_almost_equal(shepard_sim(a, b), 0.1353352832366127)\n",
    "\n",
    "a = np.array([ True, False, False,  True,  True,  True], dtype=bool)\n",
    "b = np.array([False,  True, False, False, False, False], dtype=bool)\n",
    "assert_almost_equal(shepard_sim(a, b), 0.006737946999085467)\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17d5c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: add your own test cases here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b832f60",
   "metadata": {},
   "source": [
    "Now you can use your `shepard_sim` function to compute the similarity between grapefruit and banana: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a46ae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grapefruit_features = np.array([True,  True,  True, False, True ])\n",
    "banana_features  = np.array([True, False,  False,  False, False ])\n",
    "\n",
    "print('The similarity between grapefruit and banana is: ' + str(shepard_sim(grapefruit_features, banana_features)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b17e00",
   "metadata": {},
   "source": [
    "Below, we define some test features to try. The following cell uses your function `shepard_sim` to plot the shared features between multiple arrays. \n",
    "\n",
    "It's missing some things to make it a good figure: add axes labels, axes ticks, and a title to make it clear what the image is showing. \n",
    "\n",
    "Once you have made the necessary changes to the plot (NOT the data!), save your figure as `PS7_Q3_2.png` and upload it to Gradescope. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd218d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS CELL!\n",
    "\n",
    "# Generate all possible combinations of True and False for size 3\n",
    "all_combinations = list(product([True, False], repeat=3))\n",
    "# Convert the combinations to NumPy arrays\n",
    "all_arrays = [np.array(combination) for combination in all_combinations]\n",
    "\n",
    "shared_features = np.zeros([8,8])\n",
    "\n",
    "for i in range(8):\n",
    "    for j in range(8):\n",
    "        shared_features[i,j] = int(np.log(shepard_sim(all_arrays[i],all_arrays[j])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e9c279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EDIT THIS CELL OR ADD NEW LINES TO ADD WHAT IS MISSING FROM THIS FIGURE\n",
    "\n",
    "# Plot the array as a colormap\n",
    "plt.imshow(shared_features, cmap='viridis')  # 'viridis' is just an example colormap; you can choose any other colormap\n",
    "\n",
    "# Add a colorbar for reference\n",
    "plt.colorbar()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig(\"PS7_Q3_2.png\") # uncomment this line when you have made your modifications and are ready to save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25274bba",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Q4 Applying the Prototype Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44dbb4a",
   "metadata": {},
   "source": [
    "Now that we have both a way of computing prototypes, and another way of quantifying similarity, let's revisit our animal dataset from Q2.\n",
    "\n",
    "First, let's load our data in again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2f0637",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"50animals.npz\")\n",
    "\n",
    "# create variables out of the arrays\n",
    "animal_features = data['animal_features']\n",
    "feature_names = data['feature_names']\n",
    "animal_names = data['animal_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1562f9b",
   "metadata": {},
   "source": [
    "Recall that `animal_features` is a $50\\times 80$ boolean array of features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776ff3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(animal_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367e16c1",
   "metadata": {},
   "source": [
    "And that `feature_names` is a list of length $80$ of the feature names (only the first 10 are shown here, because the list is fairly long &ndash; though feel free to take a look at the whole list if you want to!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e5cad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_names[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ee5e0b",
   "metadata": {},
   "source": [
    "And that `animal_names` is a list of length $50$ of the animal names (only showing the first 10 here, because the list is long):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec29bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(animal_names[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5763904",
   "metadata": {},
   "source": [
    "### Q4.1 Find a feature's prototype [4pts, SOLO]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78271aa5",
   "metadata": {},
   "source": [
    "Complete the function `find_feature_prototype` to take the name of a feature and find the **prototype** of the animals that have that feature, using your function `prototype`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3cf6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_feature_prototype(name, features, feature_names):\n",
    "    \"\"\"\n",
    "    Computes the prototype of all animals with a given feature.\n",
    "    \n",
    "    Hint: your solution can be done in 2 lines of code, including the\n",
    "    return statement.\n",
    "    \n",
    "    You should be using boolean indexing in your answer &ndash; refer back to\n",
    "    Problem Set 0 if you forget how to do this!\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    name : string\n",
    "        the name of a feature\n",
    "    features : boolean numpy array\n",
    "        animals by features, with shape (n, m)\n",
    "    feature_names : list of strings\n",
    "        list of feature names with length m\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    boolean numpy array of the prototype's features, with shape (m,)\n",
    "    \n",
    "    \"\"\"\n",
    "    #YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5456e186",
   "metadata": {},
   "source": [
    "Test the `find_feature_prototype` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05def550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the animal data\n",
    "data = np.load(\"50animals.npz\")\n",
    "af = data['animal_features']\n",
    "fn = data['feature_names']\n",
    "data.close()\n",
    "\n",
    "# check the coastal prototype\n",
    "coastal_prototype = find_feature_prototype('coastal habitat', af, fn)\n",
    "assert_array_equal(coastal_prototype, np.array([ True,  True,  True, False,  True, False,  True, False,  True,\n",
    "       False, False, False, False, False, False, False,  True, False,\n",
    "       False, False,  True,  True, False, False, False,  True,  True,\n",
    "       False, False, False,  True,  True, False,  True,  True, False,\n",
    "        True,  True,  True, False, False, False, False, False, False,\n",
    "        True,  True,  True, False, False,  True, False,  True, False,\n",
    "        True, False, False, False, False, False, False, False,  True,\n",
    "       False, False, False,  True,  True, False, False, False, False,\n",
    "        True,  True, False, False, False, False,  True, False], dtype=bool))\n",
    "\n",
    "for i in range(20):\n",
    "    # create a random feature array, with some generic feature names\n",
    "    n, m = np.random.randint(10, 100, 2)\n",
    "    features = np.random.randint(0, 2, (n, m)).astype(bool)\n",
    "    names = np.array([\"feature_{}\".format(j) for j in range(m)])\n",
    "    \n",
    "    # check that the prototype is correct\n",
    "    j = np.random.randint(0, m)\n",
    "    true_proto = prototype(np.array([f for f in features if f[j]]))\n",
    "    proto = find_feature_prototype('feature_{}'.format(j), features, names)\n",
    "    assert_array_equal(proto, true_proto)\n",
    "\n",
    "# check that the function uses prototype\n",
    "old_prototype = prototype\n",
    "del prototype\n",
    "try:\n",
    "    find_feature_prototype('tusks', af, fn)\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\"find_feature_prototype does not call the prototype function\")\n",
    "finally:\n",
    "    prototype = old_prototype\n",
    "    del old_prototype\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d552720b",
   "metadata": {},
   "source": [
    "Try running your function on a few different features, and see what the features are for the prototype. Copy and paste the outputs of the two cells below in Gradescope."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff223fd",
   "metadata": {},
   "source": [
    "A) \"claws\" prototype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade1dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "claws = find_feature_prototype('claws', animal_features, feature_names)\n",
    "print(\"The 'claws' prototype has the following features:\")\n",
    "print(np.array(feature_names) [claws])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367f1483",
   "metadata": {},
   "source": [
    "B) \"domesticated\" prototype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9190d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "domesticated_prototype = find_feature_prototype('domesticated', animal_features, feature_names)\n",
    "print(\"The 'domesticated' prototype has the following features:\")\n",
    "print(np.array(feature_names)[domesticated_prototype])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7d37e3",
   "metadata": {},
   "source": [
    "----\n",
    "### Q4.2 Find animals similar to a prototype [4pts, SOLO]\n",
    "\n",
    "Now, using both your `find_feature_prototype` function and your `shepard_sim` function, implement the function `find_similar_animals_prototype` to find the **five most similar animals** to the prototype.\n",
    "\n",
    "Note: just like in Q2 the `np.argsort()` function might come in handy here (take a look at Problem Set 0 if you forgot how it's used). To keep ties in the original order, make sure to use `mergesort` argument (which is [stable](http://programmers.stackexchange.com/a/247441)) like so:\n",
    "\n",
    "```\n",
    "indices = np.argsort(array, kind='mergesort')\n",
    "```\n",
    "\n",
    "Submit your code for `find_similar_animals_prototype` in Gradescope (**2 points**). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85c9c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_animals_prototype(name, features, feature_names, animal_names):\n",
    "    \"\"\"\n",
    "    Finds the five most similar animals to the prototype for the given feature.\n",
    "    You should return the animals in order from most similar to least similar\n",
    "    to the prototype. \n",
    "    \n",
    "    If two animals have the same similarity score, find_similar_animals \n",
    "    should break ties in the REVERSE of the order they appear in animal_names \n",
    "    (e.g., if the first two entries in animal_names are A and B, and both animals \n",
    "    A and B have the same similarity to target animal C, find_similar_animals should \n",
    "    place B BEFORE A when ranking them in terms of their similarity to C.)\n",
    "    \n",
    "    Hint: your solution can be done in 4 lines of code, including the return\n",
    "    statement.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    feature : string\n",
    "        the name of a feature\n",
    "    features : boolean numpy array\n",
    "        animals by features, with shape (n, m)\n",
    "    feature_names : list of strings\n",
    "        list of feature names with length m\n",
    "    animal_names : list of strings\n",
    "        list of animal names with length n\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    a list of five animal names\n",
    "    \n",
    "    \"\"\"\n",
    "    #YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebe0d00",
   "metadata": {},
   "source": [
    "Test the `find_similar_animals` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c4d39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the animal data\n",
    "data = np.load(\"50animals.npz\")\n",
    "af = data['animal_features']\n",
    "fn = data['feature_names']\n",
    "an = data['animal_names']\n",
    "data.close()\n",
    "\n",
    "# check the coastal animals\n",
    "assert_array_equal(\n",
    "    find_similar_animals_prototype('coastal habitat', af, fn, an), \n",
    "    ['dolphin', 'beaver', 'seal', 'otter', 'killer whale'])\n",
    "\n",
    "# check the tunnels animals\n",
    "assert_array_equal(\n",
    "    find_similar_animals_prototype('digs tunnels', af, fn, an),\n",
    "    ['weasel', 'mouse', 'rat', 'rabbit', 'fox'])\n",
    "\n",
    "# check the tusks animals \n",
    "assert_array_equal(\n",
    "    find_similar_animals_prototype('tusks', af, fn, an),\n",
    "    ['elephant', 'walrus', 'hippopotamus', 'ox', 'rhinoceros'])\n",
    "\n",
    "# check the aquatic animals with a different feature array\n",
    "assert_array_equal(\n",
    "    find_similar_animals_prototype('aquatic', af[:25, :40], fn[:40], an[:25]),\n",
    "    ['humpback whale', 'dolphin', 'killer whale', 'blue whale', 'elephant'])\n",
    "\n",
    "# check that the function uses find_feature_prototype\n",
    "old_find_feature_prototype = find_feature_prototype\n",
    "del find_feature_prototype\n",
    "try:\n",
    "    find_similar_animals_prototype('coastal habitat', af, fn, an)\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\"find_similar_animals does not call the prototype function\")\n",
    "finally:\n",
    "    find_feature_prototype = old_find_feature_prototype\n",
    "    del old_find_feature_prototype\n",
    "\n",
    "# check that the function uses shepard_sim\n",
    "old_shepard_sim = shepard_sim\n",
    "del shepard_sim\n",
    "try:\n",
    "    find_similar_animals_prototype('coastal habitat', af, fn, an)\n",
    "except NameError:\n",
    "    pass\n",
    "else:\n",
    "    raise AssertionError(\"find_similar_animals does not call the shepard_sim function\")\n",
    "finally:\n",
    "    shepard_sim = old_shepard_sim\n",
    "    del old_shepard_sim\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcfd803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: add your own test cases here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecf8590",
   "metadata": {},
   "source": [
    "Run the cells below and see what the five most similar animals are for the \"claws\" and \"domesticated\" prototypes you calculated above. Copy and paste the output of the two cells below into Gradescope (**1 point each**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef342ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The most similar animals to the claws prototype are:\")\n",
    "print(find_similar_animals_prototype('claws', animal_features, feature_names, animal_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4a3235",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The most similar animals to the domesticated prototype are:\")\n",
    "print(find_similar_animals_prototype('domesticated', animal_features, feature_names, animal_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f165f32",
   "metadata": {},
   "source": [
    "----\n",
    "## Q5 Evaluating the Prototype Model [5pts, SOLO]\n",
    "\n",
    "Run your `find_feature_prototype` function and see what features the 'carnivore' prototype has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735585f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "carnivore_prototype = find_feature_prototype('carnivore', animal_features, feature_names)\n",
    "print(\"The 'carnivore' prototype has features:\")\n",
    "print(np.array(feature_names)[carnivore_prototype])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af0cfb2",
   "metadata": {},
   "source": [
    "Now run your function `find_similar_animals` for the input 'carnivore':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ce15f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The five most similar animals to the 'carnivore' prototype are: \", find_similar_animals_prototype('carnivore', animal_features, feature_names, animal_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9dc371",
   "metadata": {},
   "source": [
    "Answer the following questions in Gradescope:\n",
    "\n",
    "A) What are the five most similar animals it returns to prototype of the 'carnivore' animals? (**1 point**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811f03ef",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d3d2d4",
   "metadata": {},
   "source": [
    "B) Do you agree that these animals are are similar to the prototype? Do they match your intuitions for the *most* similar animals to the prototype (that is, if you were to intuitively pick out the five animals most similar to the 'carnivore' prototype, would you pick those five in that order)? (**2 points**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770fcffd",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4cb1f2",
   "metadata": {},
   "source": [
    "C) If you answered \"yes\" above, explain what about either Shepard's law or prototypes makes this a good similarity metric. If \"no\", what about Shepard's law or prototypes causes your intuition to be challenged? (**2 points**)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12138c0",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e5408d",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #c1f2a5\">\n",
    "    \n",
    "# Part 2\n",
    "# Simple neural networks: Hebbian learning\n",
    "\n",
    "In this part, we will explore some of the simplest forms of learning in neural networks: Hebbian learning.    \n",
    "\n",
    "## Instructions\n",
    "\n",
    "\n",
    "\n",
    "Remember to do your problem set in Python 3. Fill in `#YOUR CODE HERE`.\n",
    "    \n",
    "Reminder - all questions are solo questions for this problem set.\n",
    "\n",
    "Unless we specify otherwise, make sure: \n",
    "- that all plots are scaled in such a way that you can see what is going on (while still respecting specific plotting instructions) \n",
    "- that the general patterns are fairly represented.\n",
    "- to label all x- and y-axes, and to include a title.\n",
    "    \n",
    "**Test cases are here to help you debug your code, but passing them successfully is not a guarantee that your code is correct.**\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2227137",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec60253",
   "metadata": {},
   "source": [
    "## Q6 Hebbian network weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189da819",
   "metadata": {},
   "source": [
    "One of the simplest neural network learning algorithms is Hebbian\n",
    "learning, in which the weight between two nodes is increased when\n",
    "those nodes take on the same value, and decreased when they take on\n",
    "different values. If ${\\bf x} = (x_1, \\ldots x_n)^T$ and\n",
    "${\\bf y} = (y_1, \\ldots, y_m)^T$ are $n \\times 1$ and $m \\times 1$\n",
    "vectors representing the inputs and outputs to a neural network\n",
    "respectively, the weights of the neural network can be expressed in a\n",
    "$m \\times n$ matrix ${\\bf W}$. The networks predicted output\n",
    "$\\mathbf{\\hat{y}}$ is then:\n",
    "\n",
    "\\begin{equation}      \n",
    "\\mathbf{\\hat{y}}  = \\mathbf{Wx}\n",
    "\\end{equation}\n",
    "\n",
    "We train the neural network by providing it with a set of input-output\n",
    "pairs, $({\\bf x},{\\bf y})$. Hebbian learning adjusts the weights using\n",
    "the following equation for each input-output pair:\n",
    "\n",
    "\\begin{equation}         \n",
    "\\Delta\\mathbf{W} = \\eta \\mathbf{y}\\mathbf{x}^{T}\n",
    "\\end{equation} \n",
    "        \n",
    "In other words, the change in the weight matrix $\\mathbf{W}$ is determined by\n",
    "the outer product of the output and input vectors, multiplied by the\n",
    "learning rate $\\eta$. Then, the updated weight matrix equals the old\n",
    "weight matrix plus $\\Delta\\mathbf{W}$.\n",
    "\n",
    "\\begin{equation}         \n",
    "\\mathbf{\\hat{W}} = \\mathbf{W} + \\Delta \\mathbf{W}\n",
    "\\end{equation} \n",
    "\n",
    "Another way to think about this is that each weight $w_{ij}$, which connects input neuron $j$ to output neuron $i$, is updated based on the correlation between their values:\n",
    "\n",
    "\\begin{equation}\n",
    "\\Delta{w_{ij}} = w_{ij} + \\eta y_i x_j\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87517623",
   "metadata": {},
   "source": [
    "The Hebb rule was inspired by people thinking about how neuronal interactions may enable learning, and was confirmed by experiments many years later. It is, therefore, a good example of how considering a problem at the algorithmic level can guide the investigation of the implementational, and, vice versa, how discoveries at the implementational level can confirm thoughts about the suitability of algorithmic descriptions of processes.\n",
    "\n",
    "Read more about the motivation and formulation behind the Hebb rule here: https://en.wikipedia.org/wiki/Hebbian_theory\n",
    "\n",
    "Independent of its neuronal interpretations and basis, the Hebb rule forms the basis of many systems for *unsupervised* learning, as it organizes networks based solely on the statistics of the input, rather than any teaching signal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a334e7af",
   "metadata": {},
   "source": [
    "### Q6.1 Implementing the Hebbian learning rule [4pts, HELP]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888253b0",
   "metadata": {},
   "source": [
    "Assume we want to learn what noises animals make based on their\n",
    "traits. We might list four input features:\n",
    "\n",
    "1. chasing sticks\n",
    "2. liking water \n",
    "3. having whiskers\n",
    "4. being furry\n",
    "\n",
    "Each of the features can take on one of the two different logical values: 1 (<code>TRUE</code>) and -1 (<code>FALSE</code>). \n",
    "\n",
    "Therefore, we would then represent dogs with ${\\bf x}_{\\rm dog} = ( 1, 1, 1, 1)^T$ and cats with ${\\bf x}_{\\rm cat} = (-1,-1,1,1)^T$. \n",
    "\n",
    "Likewise, we could have four output features (noise types):\n",
    "\n",
    "1. hissing\n",
    "2. barking\n",
    "3. neighing\n",
    "4. growling\n",
    "\n",
    "with ${\\bf y}_{\\rm dog} = (-1,1,-1,1)^T$ and ${\\bf y}_{\\rm cat} = (1, -1 -1, 1)^T$. Then, $(\\mathbf{x}_{\\rm dog},\\mathbf{y}_{\\rm dog})$ would be the input-output pair for dogs, and $(\\mathbf{x}_{\\rm cat},\\mathbf{y}_{\\rm cat})$ would be the input-output pair for cats. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965a118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputFeatures = ['chases sticks', 'likes water','whiskers','furry']\n",
    "outputFeatures = ['hisses','barks','neighs','growls']\n",
    "\n",
    "xDog = np.array([ 1., 1., 1., 1. ])\n",
    "xCat = np.array([ -1., -1., 1., 1. ])\n",
    "\n",
    "yDog =  np.array([ -1., 1., -1., 1. ])\n",
    "yCat = np.array([ 1., -1., -1., 1. ])\n",
    "\n",
    "trainingInputs = np.column_stack((xDog, xCat))\n",
    "trainingOutputs = np.column_stack((yDog, yCat))\n",
    "\n",
    "W = np.zeros((len(xDog),len(xDog)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c12e03",
   "metadata": {},
   "source": [
    "Complete the function `updateWeights` so that it takes in the following parameters:\n",
    "\n",
    "1. the current weight matrix $\\mathbf{W}$\n",
    "2. a matrix of training data inputs\n",
    "3. a matrix of training data outputs \n",
    "\n",
    "and returns a matrix containing weights updated using Hebbian learning on the given training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909e5706",
   "metadata": {},
   "source": [
    "The matrix of training data inputs should have training instances as\n",
    "its columns. For example, if there were two training instances,\n",
    "$\\mathbf{x}_{\\rm dog}$ and $\\mathbf{x}_{\\rm cat}$, the matrix would\n",
    "have two columns:\n",
    "$\\left[\\mathbf{x}_{\\rm dog},\\mathbf{x}_{\\rm cat}\\right]$. The matrix\n",
    "of training data outputs should have two columns corresponding to\n",
    "output instances:\n",
    "$\\left[\\mathbf{y}_{\\rm dog},\\mathbf{y}_{\\rm cat}\\right]$. The learning rate $\\eta$ is set at $.25$ inside <code>updateWeights</code> as a default.\n",
    "\n",
    "Copy your function into gradescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084fb281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateWeights(W, trainingInputs, trainingOutputs, eta = 0.25):\n",
    "    \"\"\"\n",
    "    Updates the current weight matrix W using Hebbian learning.\n",
    "    \n",
    "    Hint: your solution can be done in a single line of code, \n",
    "    including the return statement.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    W: the trained weight matrix\n",
    "    trainingInputs:  a matrix where each column represents a set of \n",
    "        input features\n",
    "    trainingOutputs: a matrix where each column represents a set of \n",
    "        output features\n",
    "    eta: the learning rate, set at 0.25 by default    \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    a matrix with the updated weight matrix after the network has seen \n",
    "        the given training data.\n",
    "\n",
    "    \"\"\"\n",
    "    #YOUR CODE HERE  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029b0f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "updatedW = updateWeights(W,trainingInputs,trainingOutputs)\n",
    "print(W)\n",
    "print(updatedW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ea9948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your own test cases here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c827c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Check that `updateWeights` produces expected output.\"\"\"\n",
    "from nose.tools import assert_equal\n",
    "from numpy.testing import assert_allclose\n",
    "\n",
    "testW0 = np.zeros((4,4))\n",
    "testInputs1 = np.array([[1, -1, 1],[1, -1, 1],[1, 1, 1],[1, 1, 1]])\n",
    "testOutputs1 = np.array([[-1, 1, 1],[1, -1, 1],[-1, -1, 1],[1, 1, 1]])\n",
    "\n",
    "testW1 = updateWeights(testW0, testInputs1[:,[0,1]],testOutputs1[:,[0,1]])\n",
    "\n",
    "\"\"\"Confirm that the output is an array\"\"\" \n",
    "assert(isinstance(testW1, np.ndarray))\n",
    "\n",
    "\"\"\"Check if dimensions are the same as the original weights\"\"\" \n",
    "assert_equal(testW1.shape, (4, 4))\n",
    "\n",
    "\"\"\"Check if weight matrix sums to 0, if trained on first two examples\"\"\" \n",
    "assert_equal(testW1.sum(),0)\n",
    "\n",
    "testW2 = updateWeights(testW0, testInputs1, testOutputs1)\n",
    "\n",
    "\"\"\"Check if weight matrix sums to 4, if trained on all three examples\"\"\" \n",
    "assert_equal(testW2.sum(),4)\n",
    "\n",
    "testW3 = updateWeights(np.zeros((3,3)), testInputs1[0:3,], testOutputs1[0:3,])\n",
    "\n",
    "\"\"\"Check if dimensions are the same as the original weights\"\"\" \n",
    "assert_equal(testW3.shape, (3, 3))\n",
    "\n",
    "\"\"\"Check if the weight matrix is correct: Input 1\"\"\" \n",
    "testW4 = updateWeights(testW0, testInputs1,testOutputs1)\n",
    "assert_allclose(testW4,np.array(\n",
    "       [[-0.25, -0.25,  0.25,  0.25],\n",
    "       [ 0.75,  0.75,  0.25,  0.25],\n",
    "       [ 0.25,  0.25, -0.25, -0.25],\n",
    "       [ 0.25,  0.25,  0.75,  0.75]]))\n",
    "\n",
    "\"\"\"Check if the weight matrix is correct: Input 2\"\"\" \n",
    "test_xDog = np.array([ 1., 1., 1., 1. ])\n",
    "test_xCat = np.array([ -1., -1., 1., 1. ])\n",
    "test_yDog =  np.array([ -1., 1., -1., 1. ])\n",
    "test_yCat = np.array([ 1., -1., -1., 1. ])\n",
    "\n",
    "testInputs2 = np.column_stack((test_xDog, test_xCat))\n",
    "testOutputs2 = np.column_stack((test_yDog, test_yCat))\n",
    "\n",
    "testW5 = updateWeights(testW0, testInputs2,testOutputs2)\n",
    "assert_allclose(testW5,np.array(\n",
    "       [[-0.5, -0.5,  0. ,  0. ],\n",
    "       [ 0.5,  0.5,  0. ,  0. ],\n",
    "       [ 0. ,  0. , -0.5, -0.5],\n",
    "       [ 0. ,  0. ,  0.5,  0.5]]))\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605911d4",
   "metadata": {},
   "source": [
    "### Q6.2 Visualizing the Hebbian network's weights [4pts, SOLO]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85c6970",
   "metadata": {},
   "source": [
    "Let's visualize different weights obtained from the `updateWeights` function.  Note that the skeleton code is provided to you in the next cell; however, the figure is missing some important components. \n",
    "\n",
    "Add 1) x-axis label, 2) y-axis label, 3) subplot titles, and 4) overall figure title. \n",
    "\n",
    "Upload your figure to gradescope as PS7_Q6_2.png."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350cd779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots with a 1x2 grid\n",
    "import matplotlib.pyplot as plt\n",
    "fig, axs = plt.subplots(1, 5, figsize=(10, 2))\n",
    "    \n",
    "im1 = axs[0].imshow(testW1, cmap='viridis')\n",
    "fig.colorbar(im1, ax=axs[0])\n",
    "im2 = axs[1].imshow(testW2, cmap='viridis')\n",
    "fig.colorbar(im2, ax=axs[1])\n",
    "im3 = axs[2].imshow(testW3, cmap='viridis')\n",
    "fig.colorbar(im3, ax=axs[2])\n",
    "im4 = axs[3].imshow(testW4, cmap='viridis')\n",
    "fig.colorbar(im4, ax=axs[3])\n",
    "im5 = axs[4].imshow(testW5, cmap='viridis')\n",
    "fig.colorbar(im5, ax=axs[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6623ca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EDIT THIS CELL OR ADD NEW LINES TO ADD WHAT IS MISSING FROM THIS FIGURE\n",
    "\n",
    "# Adjust layout to prevent clipping of titles\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig('PS7_Q6_2.png') # uncomment this line when you have made your modifications and are ready to save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e337689",
   "metadata": {},
   "source": [
    "## Q7 Making predictions [4pts, SOLO]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a8f44a",
   "metadata": {},
   "source": [
    "Calculate the network's predicted output\n",
    "($\\mathbf{\\hat{y}}$) for inputs ${\\bf x}_{\\rm dog}$ and\n",
    "${\\bf x}_{\\rm cat}$.\n",
    "\n",
    "Complete the function <code>getPredictions</code>, which takes ${\\bf x}_{\\rm dog}$, ${\\bf x}_{\\rm cat}$, and <code>updatedW</code> as parameters and returns a **dictionary** with the keys <code>yhatCat</code> and <code>yhatDog</code>, each with respective predicted binary feature arrays for cat and dog as values.\n",
    "\n",
    "If you need a refresher on dictionaries check out this link: https://docs.python.org/3/tutorial/datastructures.html#dictionaries\n",
    "\n",
    "Copy your function into gradescope.\n",
    "\n",
    "**Hint:** To double-check that your code is functioning correctly,\n",
    "these predicted outputs should be equal to their respective training\n",
    "data outputs because the training data vectors are orthogonal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3a10dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(xDog, xCat, updatedW):   \n",
    "    \"\"\"\n",
    "    Gets predicted binary feature vectors for cats and dogs\n",
    "    \n",
    "    Hint: your solution can be done in one or two lines of code, \n",
    "    including the return statement. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    xDog: the feature vector representing the input features for dog\n",
    "    xCat: the feature vector representing the input features for cat\n",
    "    updatedW: the weight matrix after training\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "    a dictionary with two key-value pairs\n",
    "        'yhatCat' ; the predicted binary features for cat \n",
    "        'yhatDog' ; the predicted binary features for dog \n",
    "\n",
    "    \"\"\"    \n",
    "    #YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7a9c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = getPredictions(xDog, xCat, updatedW)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1757ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your own test cases here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4393e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Confirm that the output is an array\"\"\" \n",
    "testPredictions = getPredictions(test_xDog, test_xCat, testW5)\n",
    "assert_equal(type(testPredictions), dict)\n",
    "\n",
    "\"\"\"Check if the keys are defined\"\"\" \n",
    "assert_equal('yhatCat' in testPredictions and 'yhatDog' \\\n",
    "    in testPredictions, True)\n",
    "\n",
    "\"\"\"Check that the vectors are binary, with 1 and -1\"\"\"\n",
    "assert(testPredictions['yhatCat'].prod() == 1 or  \\\n",
    "       testPredictions['yhatCat'].prod() == -1)\n",
    "assert(testPredictions['yhatDog'].prod() == 1 or \\\n",
    "       testPredictions['yhatDog'].prod() == -1)\n",
    "\n",
    "\"\"\"Check that the vectors are of the right length\"\"\"\n",
    "assert_equal(len(testPredictions['yhatCat']), 4)\n",
    "assert_equal(len(testPredictions['yhatDog']), 4)\n",
    "\n",
    "\"\"\"Check that the predicted output is the same as the true output\"\"\"\n",
    "assert(all(testPredictions['yhatCat'] == test_yCat))\n",
    "assert(all(testPredictions['yhatDog'] == test_yDog))\n",
    "\n",
    "\n",
    "\"\"\"Check that the predicted output for arbitrary input\"\"\"\n",
    "testInput1 = np.array([-1, -1, -1, -1])\n",
    "testInput2 = np.array([1, 1, -1, -1])\n",
    "testPredictions2 = getPredictions(testInput1, testInput2, updatedW)\n",
    "assert_allclose(testPredictions2['yhatCat'], \\\n",
    "                np.array([-1.,  1.,  1., -1.]))\n",
    "assert_allclose(testPredictions2['yhatDog'], \\\n",
    "                np.array([ 1., -1.,  1., -1.]))\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea4ddb5",
   "metadata": {},
   "source": [
    "## Q8 Incorporating uncertainty [4pts, SOLO]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aeba724",
   "metadata": {},
   "source": [
    "Now, imagine you saw an animal that was definitely furry and had\n",
    "whiskers, but you weren't sure about whether it liked water or chased\n",
    "sticks.\n",
    "\n",
    "We could represent the features of this animal as the (convex) combination:\n",
    "\n",
    "\\begin{equation}\n",
    "{\\bf x}_{\\rm unknown} = \\alpha {\\bf x}_{\\rm dog} + (1-\\alpha) {\\bf x}_{\\rm cat}\n",
    "\\end{equation}\n",
    "\n",
    "for some value of $\\alpha$ between $0$ and $1$. In other words, because we aren't certain of certain features in the ${\\bf x}_{\\rm unknown}$ vector, we can use various values of $\\alpha$ to quantify our uncertainty.\n",
    "\n",
    "Copy your function into gradescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1faf4e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWeightedPredictions(xDog, xCat, updatedW):   \n",
    "    \"\"\"\n",
    "    Get predicted binary feature vectors given a series of part-cat, \n",
    "    part-dog inputs, corresponding to alpha values of .2, .5 and .8 \n",
    "    \n",
    "    Hint: your solution can be done in about three lines of code, \n",
    "    not including the return statement. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    \n",
    "    xDog: the feature vector representing the input features for dog\n",
    "    xCat: the feature vector representing the input features for cat\n",
    "    updatedW: the weight matrix after training\n",
    " \n",
    "    Returns\n",
    "    -------\n",
    "    a dictionary with three key-value pairs\n",
    "        'yhatAnimalX2' ; the predicted binary features when alpha = .2 \n",
    "        'yhatAnimalX5' ; the predicted binary features when alpha = .5 \n",
    "        'yhatAnimalX8' ; the predicted binary features when alpha = .8 \n",
    "\n",
    "    \"\"\"    \n",
    "    #YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333d14bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "weightedPredictions = getWeightedPredictions(xDog, xCat, updatedW)\n",
    "print(weightedPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9146eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your own test cases here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2b1b45",
   "metadata": {},
   "source": [
    "## Q9 Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e2fdbd",
   "metadata": {},
   "source": [
    "### Q9.1 Interpreting weighted predictions [6pts, SOLO]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42d90cf",
   "metadata": {},
   "source": [
    "Answer the following question in Gradescope:\n",
    "\n",
    "Interpret these predictions in terms of the noises the animal might\n",
    "make. This subquestion is worth **6 points**, so give a detailed answer, stating the predictions generated and your interpretation of each (3-6 sentences).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b211bdd",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8088b087",
   "metadata": {},
   "source": [
    "### Q9.2 Hebbian learning vs. rules and symbols [4pts, SOLO]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3c84dc",
   "metadata": {},
   "source": [
    "Answer the following question in Gradescope:\n",
    "\n",
    "How does the kind of solution the neural network produces differ\n",
    "from the kind of thing we might expect from an account based on rules\n",
    "and symbols (2-4 sentences)? (**4 points**)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3bbfc4b",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d0bc9e",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #c1f2a5\">\n",
    "    \n",
    "# Part 3\n",
    "# Bayesian inference: The coin of infinite hypotheses\n",
    "\n",
    "\n",
    "## Instructions\n",
    "\n",
    "\n",
    "\n",
    "Remember to do your problem set in Python 3. Fill in `#YOUR CODE HERE`.\n",
    "    \n",
    "Reminder - all questions are solo questions for this problem set.\n",
    "\n",
    "Unless we specify otherwise, make sure: \n",
    "- that all plots are scaled in such a way that you can see what is going on (while still respecting specific plotting instructions) \n",
    "- that the general patterns are fairly represented.\n",
    "- to label all x- and y-axes, and to include a title.\n",
    "    \n",
    "**Test cases are here to help you debug your code, but passing them successfully is not a guarantee that your code is correct.**\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3d6476",
   "metadata": {},
   "source": [
    "One day, you find yourself standing in a musty room in the back of an old magic shop. Heavy velvet curtains cover the dirty windows, reluctantly letting in a few narrow beams of light, which succeed only in illuminating layers of dust suspended in the stale air. You glance around cautiously, trying not to invite scrutiny from the watchful shopkeep. Your eyes dance over row upon row of leather-bound books, resting on the rich mahogany shelves lining each wall. Who knows how long they've been here, or what ancient secrets they conceal. They almost call out to you to be opened, to divulge their long-forgotten knowledge. But no... you've come here for another reason.\n",
    "\n",
    " Before you can even turn around, the shopkeep anticipates your question. \"You've come for a coin, haven't you?\" His voice sounds strangely distant, and reminds you of some kind of large, creepy bird or something. You nod, swallowing. He totters past you, one of his legs struggling to keep up with the other. Reaching a black armoire in the corner of the room — how did you not notice it before? — he stops. The shopkeep slowly opens one of the drawers, revealing a beautiful, glimmering coin. It looks perfectly untarnished, yet, somehow, emanates the energy of centuries past. \n",
    "\n",
    " Your father's deep, soulful voice echoes in your head. \"Fetch me a coin of Azeroth, child, but only if its probability of landing heads is between 0.55 and 0.75.\"\n",
    " \n",
    " **To summarize:** a shopkeeper gets a coin out of an armoire in his magic shop, and shows it to you. You must determine if it meets your father's criteria: a probability of landing heads between 0.55 and 0.75.\n",
    "  \n",
    "  <hr/>\n",
    "  \n",
    "  Is the coin in the armoire such a coin? How can we determine if this coin matches father's request?\n",
    "\n",
    "  We can formalize your predicament by letting the variable $\\theta$ denote a coin of Azeroth's probability of landing heads on each toss, which is what you need to infer. We assume that each toss is independent of the others. In this learning problem, your hypothesis space is the set of all possible values of $\\theta$, which is all the real numbers from 0 to 1. We need to compare an infinite number of hypotheses! How can we do this?\n",
    "\n",
    "In the remaining part of the problem set, you will write functions that estimate the weight of the coin. Each function takes a single argument, a sequence of tosses, a $1 \\times n$ binary row vector representing an observed sequence of coin tosses where `1`'s represent heads and `0`'s represent tails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a819aa1",
   "metadata": {},
   "source": [
    "## Q10 Maximum Likelihood Estimation [4pts, SOLO]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503c70cc",
   "metadata": {},
   "source": [
    "Using the standard frequentist method of *maximum likelihood estimation*, define a function <code>mle_azeroth</code> that, given a sequence of tosses, returns an estimate for the value of $\\theta$ - the probability that the coin lands heads up. Remember that *MLE* relies only on data that we've actually observed, so the prior should **NOT** factor into your answer. The equation for MLE can be found in the lecture notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8c081d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mle_azeroth(sequence):\n",
    "    \"\"\"Uses MLE to estimate the value of theta.\n",
    "    \n",
    "    Hint: Your solution can be done in 1 line of code.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sequence : an (m,) Numpy array of 1s and 0s.\n",
    "        The observed sequence of coin flips.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    The value of theta, a float.\n",
    "    \n",
    "    \"\"\"\n",
    "    #YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26688bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Check that the function is correct.\"\"\"\n",
    "assert(mle_azeroth)\n",
    "\n",
    "sequence = np.array([1, 1, 0, 1, 0, 1, 1, 1, 1, 1])\n",
    "assert(mle_azeroth(sequence) == 0.8)\n",
    "\n",
    "sequence = np.array([1, 1, 1, 1, 1])\n",
    "assert(mle_azeroth(sequence) == 1.0)\n",
    "\n",
    "sequence = np.array([0, 0, 0, 0, 0])\n",
    "assert(mle_azeroth(sequence) == 0.0)\n",
    "\n",
    "sequence = np.array([1, 0])\n",
    "assert(mle_azeroth(sequence) == 0.5)\n",
    "\n",
    "sequence = np.array([1, 0, 1, 0])\n",
    "assert(mle_azeroth(sequence) == 0.5)\n",
    "\n",
    "sequence = np.array([1, 0, 1, 0, 1, 0])\n",
    "assert(mle_azeroth(sequence) == 0.5)\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0918d7d7",
   "metadata": {},
   "source": [
    "The following cell uses the <code>mle_azeroth</code> function to compute MLE for multiple coin toss sequences, and plots the obtained MLE values.\n",
    "\n",
    "The generated figure is missing important components - add all labels, including a legend, that are needed to make it clear what the figure is showing. \n",
    "\n",
    "Upload your figure to gradescope as PS7_Q10.png."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac4454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate example data\n",
    "x = np.linspace(0, 1, 11)\n",
    "y= np.zeros(11)\n",
    "z = np.ones(11)\n",
    "sequence = np.zeros(10)\n",
    "\n",
    "for i in range(10):\n",
    "    sequence[i] = 1\n",
    "    y[i+1] = mle_azeroth(sequence)\n",
    "    z[i+1] = mle_azeroth(1-sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f6db4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EDIT THIS CELL OR ADD NEW LINES TO ADD WHAT IS MISSING FROM THIS FIGURE\n",
    "    \n",
    "# Plot the three variables on the same graph\n",
    "plt.plot(x,y,label='y')\n",
    "plt.plot(x,z,label='z')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "#plt.savefig('PS7_Q10.png') # uncomment this line when you have made your modifications and are ready to save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e894eb7",
   "metadata": {},
   "source": [
    "## Q11 Maximum A Posteriori estimation [4pts, SOLO]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50b32c3",
   "metadata": {},
   "source": [
    "Assuming a **Bernoulli likelihood** and a **Beta prior**, define a function <code>map_azeroth</code> that computes the *maximum a posteriori* (MAP) estimate for $\\theta$. Your prior should be defined by two variables, `prior_heads` and `prior_tails`, which act as pseudocounts of the number of previously seen heads and tails.) The equation for computing the MAP estimate can be found in the lecture notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9815de90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_azeroth(sequence, prior_heads=0, prior_tails=0):\n",
    "    \"\"\"Computes the MAP estimate of theta.\n",
    "    \n",
    "    Hint: Your solution can be done in a line or two of code.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sequence : an (m,) Numpy array of 1s and 0s.\n",
    "        The observed sequence of coin flips.\n",
    "    prior_heads : an integer psedocount representing the\n",
    "        prior beliefs that the coin is biased towards heads.\n",
    "    prior_tails : an integer psedocount representing the\n",
    "        prior beliefs that the coin is biased towards tails.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    The value of theta, a float.\n",
    "    \n",
    "    \"\"\"\n",
    "    #YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9bfc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Check that the function exists.\"\"\"\n",
    "assert(map_azeroth)\n",
    "\n",
    "\"\"\"Check that, with no prior specified, the MAP and MLE estimates are the same.\"\"\"\n",
    "for i in range(10):\n",
    "    sequence = np.random.randint(0, 1, size=(10,))\n",
    "    assert(mle_azeroth(sequence) == map_azeroth(sequence))\n",
    "\n",
    "\"\"\"Check that changing the prior changes the estimate.\"\"\"\n",
    "sequence = np.array([1, 1, 0, 1, 0, 1, 1, 1, 1, 1])\n",
    "assert(map_azeroth(sequence) == 0.8)\n",
    "assert(map_azeroth(sequence, 1, 1) == 0.75)\n",
    "assert(map_azeroth(sequence, 5, 5) == 0.65)\n",
    "assert(map_azeroth(sequence, 1, 9) == 0.45)\n",
    "assert(map_azeroth(sequence, 15, 205) == 0.1)\n",
    "assert(map_azeroth(np.array([]), 1, 1) == 0.5)\n",
    "assert(map_azeroth(np.array([1, 0]), 1, 1) == 0.5)\n",
    "assert(map_azeroth(np.array([1, 1, 1, 1, 1, 0]), 1, 1) == 0.75)\n",
    "assert(map_azeroth(np.array([0, 0, 0, 0, 0, 1]), 1, 1) == 0.25)\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286f1719",
   "metadata": {},
   "source": [
    "The following cell uses the <code>map_azeroth</code> function to compute MAP for multiple coin toss sequences, and plots the obtained MAP values.\n",
    "\n",
    "The generated figure is missing important components - add all labels, including a legend, that are needed to make it clear what the figure is showing. \n",
    "\n",
    "Upload your figure to gradescope as PS7_Q11.png."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94834ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate example data\n",
    "x = np.linspace(0, 1, 11)\n",
    "y1= np.zeros(11)\n",
    "y2 = np.ones(11)\n",
    "y3 = np.ones(11)\n",
    "sequence = np.zeros(10)\n",
    "\n",
    "y1[0] = map_azeroth(sequence, prior_heads=5, prior_tails=10)\n",
    "y2[0] = map_azeroth(sequence, prior_heads=3, prior_tails=3)\n",
    "y3[0] = map_azeroth(sequence, prior_heads=10, prior_tails=5)\n",
    "for i in range(10):\n",
    "    sequence[i] = 1\n",
    "    y1[i+1] = map_azeroth(sequence, prior_heads=5, prior_tails=10)\n",
    "    y2[i+1] = map_azeroth(sequence, prior_heads=3, prior_tails=3)\n",
    "    y3[i+1] = map_azeroth(sequence, prior_heads=10, prior_tails=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76f53d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EDIT THIS CELL OR ADD NEW LINES TO ADD WHAT IS MISSING FROM THIS FIGURE\n",
    "    \n",
    "# Plot the three variables on the same graph\n",
    "plt.plot(x,y1,label='y1')\n",
    "plt.plot(x,y2,label='y2')\n",
    "plt.plot(x,y3,label='y3')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "#plt.savefig('PS7_Q11.png') # uncomment this line when you have made your modifications and are ready to save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb66d18",
   "metadata": {},
   "source": [
    "## Q12 Posterior mean estimate [4pts, SOLO]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed6b9b2",
   "metadata": {},
   "source": [
    "Assuming a **Bernoulli likelihood** and a **Beta prior**, define a function <code>pm_azeroth</code> that computes the *posterior mean* estimate for $\\theta$. Your prior should be defined by two variables, `prior_heads` and `prior_tails`, which act as pseudo-counts of the number of previously seen heads and tails.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f75d812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pm_azeroth(sequence, prior_heads=0, prior_tails=0):\n",
    "    \"\"\"Computes the posterior mean estimate of theta.\n",
    "    \n",
    "    Hint: Your solution can be done in a line or two of code.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    sequence : an (m,) Numpy array of 1s and 0s.\n",
    "        The observed sequence of coin flips.\n",
    "    prior_heads : an integer psedocount representing the\n",
    "        prior beliefs that the coin is biased towards heads.\n",
    "    prior_tails : an integer psedocount representing the\n",
    "        prior beliefs that the coin is biased towards tails.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    The value of theta, a float.\n",
    "    \n",
    "    \"\"\"\n",
    "    #YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19a8f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Check that the function exists.\"\"\"\n",
    "assert(pm_azeroth)\n",
    "\n",
    "\n",
    "\"\"\"Check that changing the prior changes the estimate.\"\"\"\n",
    "sequence = np.array([1, 1, 0, 1, 0, 1, 1, 1, 1, 1])\n",
    "assert(pm_azeroth(sequence) == 0.75)\n",
    "assert(pm_azeroth(sequence, 1, 7) == 0.5)\n",
    "assert(pm_azeroth(sequence, 7, 1) == 0.8)\n",
    "assert(pm_azeroth(sequence, 27, 1) == 0.9)\n",
    "assert(pm_azeroth(sequence, 124, 130) == 0.5)\n",
    "assert(pm_azeroth(np.array([]), 1, 1) == 0.5)\n",
    "assert(pm_azeroth(np.array([1, 0]), 1, 1) == 0.5)\n",
    "assert(pm_azeroth(np.array([1, 1, 1, 1, 1, 0]), 1, 1) == 0.70)\n",
    "assert(pm_azeroth(np.array([0, 0, 0, 0, 0, 1]), 1, 1) == 0.30)\n",
    "\n",
    "print(\"Success!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f780e3ef",
   "metadata": {},
   "source": [
    "The following cell uses the <code>pm_azeroth</code> function to compute posterior means for multiple coin toss sequences and priors, and plots the obtained posterior means values.\n",
    "\n",
    "The generated figure is missing important components - add all labels, including a legend, that are needed to make it clear what the figure is showing. \n",
    "\n",
    "Upload your figure to gradescope as PS7_Q12.png."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d64acad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate example data\n",
    "x = np.linspace(0, 1, 11)\n",
    "y= np.zeros(11)\n",
    "\n",
    "sequence = np.zeros(10)\n",
    "y1[0] = map_azeroth(sequence, prior_heads=5, prior_tails=10)\n",
    "y2[0] = map_azeroth(sequence, prior_heads=100, prior_tails=100)\n",
    "y3[0] = map_azeroth(sequence, prior_heads=10, prior_tails=5)\n",
    "for i in range(10):\n",
    "    sequence[i] = 1\n",
    "    y1[i+1] = pm_azeroth(sequence, prior_heads=5, prior_tails=10)\n",
    "    y2[i+1] = pm_azeroth(sequence, prior_heads=100, prior_tails=100)\n",
    "    y3[i+1] = pm_azeroth(sequence, prior_heads=10, prior_tails=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f4e86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: EDIT THIS CELL OR ADD NEW LINES TO ADD WHAT IS MISSING FROM THIS FIGURE\n",
    "   \n",
    "# Plot the three variables on the same graph\n",
    "plt.plot(x,y1,label='y1')\n",
    "plt.plot(x,y2,label='y2')\n",
    "plt.plot(x,y3,label='y3')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "#plt.savefig('PS7_Q12.png') # uncomment this line when you have made your modifications and are ready to save the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08440db7",
   "metadata": {},
   "source": [
    "## Q13 Drawing conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab421d9",
   "metadata": {},
   "source": [
    "### Q13.1 MLE vs. MAP vs. posterior mean [3pts, SOLO]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110a65a0",
   "metadata": {},
   "source": [
    "Assume you tossed a coin of Azeroth 10 times and observed the specific sequence `HHTHTHHHHH`. Further assume that we've observed some fictitious trials and have a prior belief that coins of Azeroth are slightly biased towards landing heads. Thus, let $V_H$ = 55 and $V_T$ = 45, denoting that in the past we've observed the coin of Azeroth flipped 100 times and saw 55 heads and 45 tails.\n",
    "\n",
    "Let's see the results of our estimators by running the next cell.\n",
    "\n",
    "Copy the numbers printed out by the next cell into the appropriate fields in Gradescope. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe9d339",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = np.array([1, 1, 0, 1, 0, 1, 1, 1, 1, 1])\n",
    "print(\"MLE: {}\".format(mle_azeroth(sequence)))\n",
    "print(\"MAP: {}\".format(map_azeroth(sequence, prior_heads=55, prior_tails=45)))\n",
    "print(\"Posterior mean: {}\".format(pm_azeroth(sequence, prior_heads=55, prior_tails=45)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab75b52e",
   "metadata": {},
   "source": [
    "### Q13.2 Evaluating the coin's bias [4pts, SOLO]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00699f9c",
   "metadata": {},
   "source": [
    "Answer the following question in Gradescope:\n",
    "\n",
    "Given the father's request for a coin with probability of landing heads between $0.55$ and $0.75$ - do you think you should you take this coin? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38a3a3f",
   "metadata": {},
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbcf8557",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #c1f2a5\">\n",
    "\n",
    "# Submission\n",
    "\n",
    "\n",
    "Before turning this problem set in remember to do the following steps:\n",
    "\n",
    "1. **Restart the kernel** (Kernel$\\rightarrow$Restart)\n",
    "2. **Run all cells** (Cell$\\rightarrow$Run All)\n",
    "3. **Save** (File$\\rightarrow$Save and Checkpoint)\n",
    "\n",
    "    \n",
    "After you have completed these three steps, ensure that the following cell has printed \"No errors\". If it has <b>not</b> printed \"No errors\", then your code has a bug in it and has thrown an error! Make sure you fix this error before turning in your problem set.\n",
    "    \n",
    "When you've made sure there are no issues in your code:\n",
    "- Upload your answers in Gradescope's PS7.\n",
    "- Convert your Jupyter Notebook into a `.py` file by doing so:    \n",
    "    \n",
    "</div>\n",
    "\n",
    "\n",
    "<center>    \n",
    "  <img src=\"../img/py_exporting_instructions.png\" width=\"500\"/>\n",
    "</center>\n",
    "\n",
    "<div style=\"background-color: #c1f2a5\">\n",
    "    \n",
    "- Submit the `.py` file you just created in Gradescope's PS6-code.\n",
    "    \n",
    "</div>        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fb28aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
